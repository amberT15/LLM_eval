{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mt_preprocess\n",
    "import h5py\n",
    "import numpy as np\n",
    "import example\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11840/11840 [00:04<00:00, 2479.94it/s]\n",
      "100%|██████████| 1088/1088 [00:00<00:00, 2523.11it/s]\n",
      "100%|██████████| 38028/38028 [00:15<00:00, 2474.24it/s]\n"
     ]
    }
   ],
   "source": [
    "file = h5py.File('../../data/mtsplice/seq.h5','w')\n",
    "\n",
    "for set in ['test','valid','train']:\n",
    "    seq_cache=[]\n",
    "    target_cache=[]\n",
    "    mean_cache = []\n",
    "    data_loader = mt_preprocess.Ascot('../../data/mtsplice/gtex_'+set+'_psi.csv',\n",
    "                                    '/home/ztang/ref/hg38/hg38.fa',\n",
    "                                    length = 400,\n",
    "                                    tissues=mt_preprocess.tissues,\n",
    "                                    encode=True,\n",
    "                                    pad_trim_same_l=False,\n",
    "                                    flanking=300,\n",
    "                                    flanking_exons=False,\n",
    "                                    region_anno=False,\n",
    "                                    seq_align='both',\n",
    "                                    mean_inpute=False,\n",
    "                                    use_logit=True)\n",
    "    len = data_loader.__len__()\n",
    "    for i in tqdm(range(len)):\n",
    "        item = data_loader.__getitem__(i)\n",
    "        target = item[1]\n",
    "        seq = np.concatenate((item[0]['seql'],item[0]['seqr']))\n",
    "        seq_cache.append(seq)\n",
    "        target_cache.append(target)\n",
    "        mean_cache.append(item[0]['mean'])\n",
    "\n",
    "    file.create_dataset('x_'+set, data= np.array(seq_cache))\n",
    "    file.create_dataset('y_'+set, data = np.array(target_cache))\n",
    "    file.create_dataset('m_'+set, data = np.array(mean_cache))\n",
    "\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11840/11840 [00:04<00:00, 2434.93it/s]\n",
      "100%|██████████| 1088/1088 [00:00<00:00, 2441.32it/s]\n",
      "100%|██████████| 38028/38028 [00:15<00:00, 2436.26it/s]\n"
     ]
    }
   ],
   "source": [
    "file = h5py.File('../../data/mtsplice/delta_logit.h5','w')\n",
    "\n",
    "for set in ['test','valid','train']:\n",
    "    seq_cache=[]\n",
    "    target_cache=[]\n",
    "    data_loader = mt_preprocess.Ascot('../../data/mtsplice/gtex_'+set+'_psi.csv',\n",
    "                                    '/home/ztang/ref/hg38/hg38.fa',\n",
    "                                    length = 400,\n",
    "                                    tissues=mt_preprocess.tissues,\n",
    "                                    encode=True,\n",
    "                                    pad_trim_same_l=False,\n",
    "                                    flanking=300,\n",
    "                                    flanking_exons=False,\n",
    "                                    region_anno=False,\n",
    "                                    seq_align='both',\n",
    "                                    mean_inpute=False,\n",
    "                                    use_logit=True)\n",
    "    len = data_loader.__len__()\n",
    "    for i in tqdm(range(len)):\n",
    "        item = data_loader.__getitem__(i)\n",
    "        target = item[1]\n",
    "        mean = item[0]['mean']\n",
    "        target = target - mean\n",
    "        target_m = np.vstack((target,mean))\n",
    "        seq = np.concatenate((item[0]['seql'],item[0]['seqr']))\n",
    "        seq_cache.append(seq)\n",
    "        target_cache.append(target_m.T)\n",
    "\n",
    "    file.create_dataset('x_'+set, data= np.array(seq_cache))\n",
    "    file.create_dataset('y_'+set, data = np.array(target_cache))\n",
    "\n",
    "file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('old_tf': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ca0d8e8b539da0244e0291643a867b2adfdaa50f1c8989ffdc5da760d406378"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
