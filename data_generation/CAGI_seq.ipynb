{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-14 14:23:51.786595: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, h5py\n",
    "import pandas as pd\n",
    "from gopher import variant_effect\n",
    "length = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read df and add strand\n",
    "all_dfs = []\n",
    "cagi_data = '../data/CAGI/raw/'\n",
    "combined_filename = '../data/CAGI/combined_cagi.bed'\n",
    "for filename in os.listdir(cagi_data):\n",
    "    prefix, regulator = filename.split('.tsv')[0].split('_')\n",
    "\n",
    "    one_reg = pd.read_csv(os.path.join(cagi_data,filename), skiprows=7, sep='\\t', header=None)\n",
    "    one_reg['regulator'] = regulator\n",
    "    one_reg['set'] = prefix\n",
    "    all_dfs.append(one_reg)\n",
    "    \n",
    "\n",
    "combined_cagi = pd.concat(all_dfs)\n",
    "combined_cagi.insert(4, 'strand', '+')\n",
    "combined_cagi.insert(2,'end',combined_cagi.iloc[:,1]+1)\n",
    "combined_cagi.iloc[:,0] = 'chr'+combined_cagi.iloc[:,0].astype(str)\n",
    "combined_cagi.to_csv(combined_filename, sep='\\t', header=False, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = '../data/CAGI/'+str(length)+'/cagi.bed'\n",
    "variant_effect.expand_range(combined_filename, output_filename,window = length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa_filename = '../data/CAGI/'+str(length)+'/cagi.fa'\n",
    "coords_list, seqs_list = variant_effect.convert_bed_to_seq(output_filename, fa_filename, genomefile='/home/ztang/ref/hg19/hg19.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = length\n",
    "bad_lines = []\n",
    "N = len(seqs_list)\n",
    "nonneg_df = pd.read_csv(output_filename, sep='\\t', header=None)\n",
    "mid = window // 2\n",
    "onehot_ref = []\n",
    "onehot_alt = []\n",
    "coord_np = np.empty((N, 4)) # chrom, start, end coordinate array\n",
    "pos_dict = {'+': int(length/2-1), '-':int(length/2)}\n",
    "for i,(chr_s_e, seq) in enumerate(zip(coords_list, seqs_list)):\n",
    "    alt = ''\n",
    "    strand = chr_s_e.split('(')[-1].split(')')[0]\n",
    "    pos = pos_dict[strand]\n",
    "#     coord_np[i,3] = pos_dict[strand] - 1535\n",
    "\n",
    "    if seq[pos] != nonneg_df.iloc[i, 3]:\n",
    "#         print('Error in line ' + str(i))\n",
    "        bad_lines.append(i)\n",
    "    else:\n",
    "        alt = nonneg_df.iloc[i,4]\n",
    "\n",
    "        onehot = variant_effect.dna_one_hot(seq)\n",
    "        mutated_onehot = onehot.copy()\n",
    "        mutated_onehot[pos] = variant_effect.dna_one_hot(alt)[0]\n",
    "        onehot_ref.append(onehot)\n",
    "\n",
    "        onehot_alt.append(mutated_onehot) \n",
    "\n",
    "onehot_alt = np.array(onehot_alt)\n",
    "onehot_ref = np.array(onehot_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_df = nonneg_df[~nonneg_df.index.isin(bad_lines)]\n",
    "included_df.to_csv('../data/CAGI/'+str(length)+'/final_cagi_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_ref_alt = h5py.File('../data/CAGI/'+str(length)+'/CAGI_onehot.h5', 'w')\n",
    "onehot_ref_alt.create_dataset('ref', data=onehot_ref)\n",
    "onehot_ref_alt.create_dataset('alt', data=onehot_alt)\n",
    "onehot_ref_alt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18442"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(onehot_ref)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Sanity check that only one nucleotide is different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2047,    0],\n",
       "       [2047,    2]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_ref_alt = h5py.File('../data/CAGI/4096/CAGI_onehot.h5', 'r')\n",
    "np.argwhere(onehot_ref_alt['ref'][0,:,:] != onehot_ref_alt['alt'][0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0.], dtype=float16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_ref_alt['ref'][0,2047,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
