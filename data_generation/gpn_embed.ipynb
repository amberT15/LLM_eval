{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpn.model\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from transformers import AutoModel, AutoModelForMaskedLM, AutoTokenizer\n",
    "import h5py\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "model = AutoModel.from_pretrained(\"../model/GPN_human/checkpoint-2000000\").to('cuda')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../model/GPN_human/checkpoint-2000000\")\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lenti-MPRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype = 'HepG2'\n",
    "\n",
    "file = h5py.File('../data/lenti_MPRA/'+celltype+'_data.h5','r')\n",
    "gpn_output = h5py.File('../data/lenti_MPRA_embed/gpn_'+celltype+'.h5','w')\n",
    "batch_size = 32\n",
    "output_cache = []\n",
    "for i in tqdm(range(0,len(file['seq']),batch_size)):\n",
    "\n",
    "    seq = file['seq'][i:i+batch_size].astype('U230')\n",
    "    input_ids = tokenizer(seq.tolist(), return_tensors=\"pt\", return_attention_mask=False, return_token_type_ids=False)[\"input_ids\"]\n",
    "    with torch.no_grad():\n",
    "        output_seq = model(input_ids.to('cuda')).last_hidden_state.cpu().detach().numpy()\n",
    "    output_cache.extend(output_seq)\n",
    "gpn_output.create_dataset(name='seq',data = np.array(output_cache))\n",
    "gpn_output.create_dataset(name='mean',data = file['mean'][:])\n",
    "gpn_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chip/Clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob('../data/chip/*.h5')\n",
    "for file in file_list:\n",
    "    tf_name = file.split('/')[-1][:-7]\n",
    "    gpn_output = h5py.File('../data/chip/GPN/'+tf_name+'_200.h5','w')\n",
    "    batch_size = 32\n",
    "    file = h5py.File(file,'r')\n",
    "    for label in ('train','valid','test'):\n",
    "        output_cache = []  \n",
    "        for i in tqdm(range(0,len(file['x_'+label]),batch_size)):\n",
    "            seq = file['x_'+label][i:i+batch_size].astype('int')\n",
    "            seq = np.transpose(seq,(0,2,1))\n",
    "            seq = utils.onehot_to_seq(seq)\n",
    "            input_ids = tokenizer(seq, return_tensors=\"pt\", return_attention_mask=False, return_token_type_ids=False)[\"input_ids\"]\n",
    "            with torch.no_grad():\n",
    "                output_seq = model(input_ids.to('cuda')).last_hidden_state.cpu().detach().numpy()\n",
    "            output_cache.extend(output_seq)\n",
    "        gpn_output.create_dataset(name='x_'+label,data = np.array(output_cache),dtype = 'float32')\n",
    "        gpn_output.create_dataset(name='x_'+label,data = file['y_'+label][:],dtype='int') \n",
    "    gpn_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob('../data/eclip/*.h5')\n",
    "for file in file_list:\n",
    "    tf_name = file.split('/')[-1][:-7]\n",
    "    gpn_output = h5py.File('../data/eclip/GPN/'+tf_name+'_200.h5','w')\n",
    "    batch_size = 32\n",
    "    file = h5py.File(file,'r')\n",
    "    for label in ('train','valid','test'):\n",
    "        output_cache = []  \n",
    "        for i in tqdm(range(0,len(file['X_'+label]),batch_size)):\n",
    "            seq = file['X_'+label][i:i+batch_size].astype('int')\n",
    "            seq = np.transpose(seq,(0,2,1))\n",
    "            seq = utils.onehot_to_seq(seq)\n",
    "            input_ids = tokenizer(seq, return_tensors=\"pt\", return_attention_mask=False, return_token_type_ids=False)[\"input_ids\"]\n",
    "            with torch.no_grad():\n",
    "                output_seq = model(input_ids.to('cuda')).last_hidden_state.cpu().detach().numpy()\n",
    "            output_cache.extend(output_seq)\n",
    "        gpn_output.create_dataset(name='x_'+label,data = np.array(output_cache),dtype = 'float32')\n",
    "        gpn_output.create_dataset(name='y_'+label,data = file['Y_'+label][:],dtype='int') \n",
    "    gpn_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MTSplice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('../data/mtsplice/delta_logit.h5','r')\n",
    "gpn_output = h5py.File('../data/mtsplice/gpn_mt.h5','w')\n",
    "batch_size = 32\n",
    "for label in ('valid','test','train'):\n",
    "    l_cache = []\n",
    "    r_cache = [] \n",
    "    for i in tqdm(range(0,len(file['x_'+label]),batch_size)):\n",
    "        seq = file['x_'+label][i:i+batch_size].astype('int')\n",
    "        seq = utils.onehot_to_seq(seq)\n",
    "        clean_seq = [s if 'N' not in s else s.replace('N','[PAD]') for s in seq ]\n",
    "        input_ids = tokenizer(clean_seq, return_tensors=\"pt\", return_attention_mask=False, return_token_type_ids=False)[\"input_ids\"]\n",
    "        l_input = input_ids[:,:400]\n",
    "        r_input = input_ids[:,400:]\n",
    "        with torch.no_grad():\n",
    "            l_output = model(l_input.to('cuda')).last_hidden_state.cpu().detach().numpy()\n",
    "            r_output = model(r_input.to('cuda')).last_hidden_state.cpu().detach().numpy()\n",
    "        l_cache.extend(l_output)\n",
    "        r_cache.extend(r_output)\n",
    "    gpn_output.create_dataset(name='xl_'+label,data = np.array(l_cache),dtype = 'float32')\n",
    "    gpn_output.create_dataset(name='xr_'+label,data = np.array(r_cache),dtype = 'float32')\n",
    "    gpn_output.create_dataset(name='y_'+label,data = file['y_'+label][:],dtype='float32') \n",
    "gpn_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERT-seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = h5py.File('../data/rna_stable/insert_dataset.h5','r')\n",
    "gpn_output = h5py.File('../data/rna_stable/gpn_human_embed.h5','w')\n",
    "batch_size = 32\n",
    "for dataset in ['test','train','valid']:\n",
    "    key = 'X_'+dataset\n",
    "    onehot = file[key]\n",
    "    string_seq = utils.onehot_to_seq(onehot)\n",
    "\n",
    "    token_seq = tokenizer.batch_encode_plus(string_seq, max_length=512,padding = 'max_length')\n",
    "    output_cache = []\n",
    "    for seq_i in tqdm(range(0,len(token_seq['input_ids']),batch_size)):\n",
    "        seq_batch = torch.tensor(token_seq['input_ids'][seq_i:seq_i+batch_size]).to('cuda')\n",
    "        output_seq = model(seq_batch).last_hidden_state.cpu().detach().numpy()\n",
    "        output_cache.extend(output_seq[:,:173,:])\n",
    "    gpn_output.create_dataset(name=key,data = np.array(output_cache))\n",
    "    gpn_output.create_dataset(name='Y_'+dataset,data = file['Y_'+dataset][:])\n",
    "    gpn_output.close()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
