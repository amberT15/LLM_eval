{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 14:22:04.159220: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 14:22:06.461571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 73741 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:07:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('../model/RBP_pretrain_1k.h5')\n",
    "input_layer = model.input \n",
    "embed_layer = model.layers[-10].output\n",
    "embed_model = tf.keras.models.Model(input_layer,embed_layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## alternative splicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-28 14:22:29.063643: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 1s 793us/step\n",
      "34/34 [==============================] - 0s 835us/step\n",
      "370/370 [==============================] - 0s 783us/step\n",
      "370/370 [==============================] - 0s 804us/step\n",
      "1189/1189 [==============================] - 1s 835us/step\n",
      "1189/1189 [==============================] - 1s 801us/step\n"
     ]
    }
   ],
   "source": [
    "rbp_output = h5py.File('../data/alternative_splicing/rbp_splice.h5','w')\n",
    "file = h5py.File('../data/alternative_splicing/delta_logit.h5','r')\n",
    "batch_size = 32\n",
    "pad_size = (1000-400)/2\n",
    "for label in ('valid','test','train'):\n",
    "    onehot = file['x_'+label]\n",
    "    l_seq = onehot[:,:400]\n",
    "    r_seq = onehot[:,400:]\n",
    "    l_pad = np.pad(l_seq,((0,0),(math.floor(pad_size),math.ceil(pad_size)),(0,0)))\n",
    "    r_pad = np.pad(r_seq,((0,0),(math.floor(pad_size),math.ceil(pad_size)),(0,0)))\n",
    "    l_embed = embed_model.predict(l_pad)\n",
    "    r_embed = embed_model.predict(r_pad)\n",
    "\n",
    "    rbp_output.create_dataset(name='xl_'+label,data = np.array(l_embed),dtype = 'float32')\n",
    "    rbp_output.create_dataset(name='xr_'+label,data = np.array(r_embed),dtype = 'float32')\n",
    "    rbp_output.create_dataset(name='y_'+label,data = file['y_'+label][:],dtype='float32') \n",
    "rbp_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INSERT-seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 845us/step\n",
      "286/286 [==============================] - 0s 1ms/step\n",
      "36/36 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "rbp_output = h5py.File('../data/RNAenlong/rbp_embed.h5','w')\n",
    "file = h5py.File('../data/RNAenlong/insert_dataset.h5','r')\n",
    "batch_size = 32\n",
    "pad_size = (1000-file['X_train'].shape[1])/2\n",
    "for dataset in ['test','train','valid']:\n",
    "    key = 'X_'+dataset\n",
    "    onehot = file[key][:]\n",
    "    pad_onehot = np.pad(onehot,((0,0),(math.floor(pad_size),math.ceil(pad_size)),(0,0)))\n",
    "    embed = embed_model.predict(pad_onehot)        \n",
    "    rbp_output.create_dataset(name=key,data = np.array(embed))\n",
    "    rbp_output.create_dataset(name='Y_'+dataset,data = file['Y_'+dataset][:])\n",
    "rbp_output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
