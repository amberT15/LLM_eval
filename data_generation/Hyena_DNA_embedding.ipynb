{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ztang/.conda/envs/torch_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import torch\n",
    "import glob\n",
    "import utils\n",
    "from transformers import PreTrainedModel\n",
    "import re\n",
    "from standalone_hyenadna import HyenaDNAModel\n",
    "from standalone_hyenadna import CharacterTokenizer\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import h5py \n",
    "import scipy.stats\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "\n",
    "def inject_substring(orig_str):\n",
    "    \"\"\"Hack to handle matching keys between models trained with and without\n",
    "    gradient checkpointing.\"\"\"\n",
    "\n",
    "    # modify for mixer keys\n",
    "    pattern = r\"\\.mixer\"\n",
    "    injection = \".mixer.layer\"\n",
    "\n",
    "    modified_string = re.sub(pattern, injection, orig_str)\n",
    "\n",
    "    # modify for mlp keys\n",
    "    pattern = r\"\\.mlp\"\n",
    "    injection = \".mlp.layer\"\n",
    "\n",
    "    modified_string = re.sub(pattern, injection, modified_string)\n",
    "\n",
    "    return modified_string\n",
    "\n",
    "# helper 2\n",
    "def load_weights(scratch_dict, pretrained_dict, checkpointing=False):\n",
    "    \"\"\"Loads pretrained (backbone only) weights into the scratch state dict.\"\"\"\n",
    "\n",
    "    # loop thru state dict of scratch\n",
    "    # find the corresponding weights in the loaded model, and set it\n",
    "\n",
    "    # need to do some state dict \"surgery\"\n",
    "    for key, value in scratch_dict.items():\n",
    "        if 'backbone' in key:\n",
    "            # the state dicts differ by one prefix, '.model', so we add that\n",
    "            key_loaded = 'model.' + key\n",
    "            # breakpoint()\n",
    "            # need to add an extra \".layer\" in key\n",
    "            if checkpointing:\n",
    "                key_loaded = inject_substring(key_loaded)\n",
    "            try:\n",
    "                scratch_dict[key] = pretrained_dict[key_loaded]\n",
    "            except:\n",
    "                raise Exception('key mismatch in the state dicts!')\n",
    "\n",
    "    # scratch_dict has been updated\n",
    "    return scratch_dict\n",
    "\n",
    "class HyenaDNAPreTrainedModel(PreTrainedModel):\n",
    "    \"\"\"\n",
    "    An abstract class to handle weights initialization and a simple interface for downloading and loading pretrained\n",
    "    models.\n",
    "    \"\"\"\n",
    "    base_model_prefix = \"hyenadna\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        pass\n",
    "\n",
    "    def forward(self, input_ids, **kwargs):\n",
    "        return self.model(input_ids, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_pretrained(cls,\n",
    "                        path,\n",
    "                        model_name,\n",
    "                        download=False,\n",
    "                        config=None,\n",
    "                        device='cpu',\n",
    "                        use_head=False,\n",
    "                        n_classes=2,\n",
    "                      ):\n",
    "        # first check if it is a local path\n",
    "        pretrained_model_name_or_path = os.path.join(path, model_name)\n",
    "        if os.path.isdir(pretrained_model_name_or_path) and download == False:\n",
    "            if config is None:\n",
    "                config = json.load(open(os.path.join(pretrained_model_name_or_path, 'config.json')))\n",
    "        else:\n",
    "            hf_url = f'https://huggingface.co/LongSafari/{model_name}'\n",
    "\n",
    "            subprocess.run(f'rm -rf {pretrained_model_name_or_path}', shell=True)\n",
    "            command = f'mkdir -p {path} && cd {path} && git lfs install && git clone {hf_url}'\n",
    "            subprocess.run(command, shell=True)\n",
    "\n",
    "            if config is None:\n",
    "                config = json.load(open(os.path.join(pretrained_model_name_or_path, 'config.json')))\n",
    "\n",
    "        scratch_model = HyenaDNAModel(**config, use_head=use_head, n_classes=n_classes)  # the new model format\n",
    "        loaded_ckpt = torch.load(\n",
    "            os.path.join(pretrained_model_name_or_path, 'weights.ckpt'),\n",
    "            map_location=torch.device(device)\n",
    "        )\n",
    "\n",
    "        # need to load weights slightly different if using gradient checkpointing\n",
    "        if config.get(\"checkpoint_mixer\", False):\n",
    "            checkpointing = config[\"checkpoint_mixer\"] == True or config[\"checkpoint_mixer\"] == True\n",
    "        else:\n",
    "            checkpointing = False\n",
    "\n",
    "        # grab state dict from both and load weights\n",
    "        state_dict = load_weights(scratch_model.state_dict(), loaded_ckpt['state_dict'], checkpointing=checkpointing)\n",
    "\n",
    "        # scratch model has now been updated\n",
    "        scratch_model.load_state_dict(state_dict)\n",
    "        print(\"Loaded pretrained weights ok!\")\n",
    "        return scratch_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights ok!\n"
     ]
    }
   ],
   "source": [
    "pretrained_model_name = 'hyenadna-tiny-1k-d256'\n",
    "max_length = 1_000\n",
    "\n",
    "model = HyenaDNAPreTrainedModel.from_pretrained(\n",
    "    './checkpoints',\n",
    "    pretrained_model_name,\n",
    ").to('cuda')\n",
    "model.eval()\n",
    "\n",
    "# create tokenizer, no training involved :)\n",
    "tokenizer = CharacterTokenizer(\n",
    "    characters=['A', 'C', 'G', 'T', 'N'],  # add DNA characters\n",
    "    model_max_length=max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lenti-MPRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "celltype = 'K562'\n",
    "file = h5py.File('/home/ztang/multitask_RNA/data/lenti_MPRA/'+celltype+'_data.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1768/1768 [01:06<00:00, 26.52it/s]\n"
     ]
    }
   ],
   "source": [
    "hidden_output = h5py.File('../data/lenti_MPRA_embed/hyena_'+celltype+'.h5','w')\n",
    "batch_size = 128\n",
    "output_cache = []\n",
    "for i in tqdm(range(0,len(file['seq']),batch_size)):\n",
    "  seq = file['seq'][i:i+batch_size].astype('U230')\n",
    "  tok_seq = tokenizer(list(seq),return_tensors=\"pt\")[\"input_ids\"].to('cuda')\n",
    "  with torch.inference_mode():\n",
    "    embeddings = model(tok_seq).cpu().detach().numpy()\n",
    "    output_cache.extend(embeddings)\n",
    "hidden_output.create_dataset(name='seq',data = np.array(output_cache))\n",
    "hidden_output.create_dataset(name='mean',data = file['mean'][:])\n",
    "hidden_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chip/Clip seq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'x_train' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/ztang/LLM_eval/data_generation/Hyena_DNA_embedding.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgalaxy1/home/ztang/LLM_eval/data_generation/Hyena_DNA_embedding.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bgalaxy1/home/ztang/LLM_eval/data_generation/Hyena_DNA_embedding.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     output_cache \u001b[39m=\u001b[39m []  \n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bgalaxy1/home/ztang/LLM_eval/data_generation/Hyena_DNA_embedding.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(file[\u001b[39m'\u001b[39;49m\u001b[39mx_\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mlabel]),batch_size)):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgalaxy1/home/ztang/LLM_eval/data_generation/Hyena_DNA_embedding.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m         seq \u001b[39m=\u001b[39m file[\u001b[39m'\u001b[39m\u001b[39mx_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mlabel][i:i\u001b[39m+\u001b[39mbatch_size]\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mint\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bgalaxy1/home/ztang/LLM_eval/data_generation/Hyena_DNA_embedding.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m         seq \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtranspose(seq,(\u001b[39m0\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/torch_env/lib/python3.11/site-packages/h5py/_hl/group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid HDF5 object reference\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(name, (\u001b[39mbytes\u001b[39m, \u001b[39mstr\u001b[39m)):\n\u001b[0;32m--> 357\u001b[0m     oid \u001b[39m=\u001b[39m h5o\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_e(name), lapl\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lapl)\n\u001b[1;32m    358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAccessing a group is done with bytes or str, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mnot \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:190\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'x_train' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "file_list = glob.glob('../data/chip/*.h5')\n",
    "for file in file_list:\n",
    "    tf_name = file.split('/')[-1][:-7]\n",
    "    hyena_output = h5py.File('../data/chip/Hyena/'+tf_name+'_200.h5','w')\n",
    "    batch_size = 128\n",
    "    file = h5py.File(file,'r')\n",
    "    for label in ('train','valid','test'):\n",
    "        output_cache = []  \n",
    "        for i in tqdm(range(0,len(file['x_'+label]),batch_size)):\n",
    "            seq = file['x_'+label][i:i+batch_size].astype('int')\n",
    "            seq = np.transpose(seq,(0,2,1))\n",
    "            seq = utils.onehot_to_seq(seq)\n",
    "            input_ids = tokenizer(list(seq), return_tensors=\"pt\",)[\"input_ids\"].to('cuda')\n",
    "            with torch.inference_mode():\n",
    "                hidden_states = model(input_ids).cpu().detach().numpy()\n",
    "            output_cache.extend(hidden_states)\n",
    "        hyena_output.create_dataset(name='x_'+label,data = np.array(output_cache),dtype = 'float32')\n",
    "        hyena_output.create_dataset(name='y_'+label,data = file['y_'+label][:],dtype='int') \n",
    "    hyena_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:01<00:00, 18.05it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 20.56it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 17.90it/s]\n",
      "100%|██████████| 89/89 [00:05<00:00, 15.55it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 18.46it/s]\n",
      "100%|██████████| 26/26 [00:01<00:00, 18.79it/s]\n",
      "100%|██████████| 80/80 [00:05<00:00, 15.97it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 19.34it/s]\n",
      "100%|██████████| 23/23 [00:01<00:00, 18.53it/s]\n",
      "100%|██████████| 38/38 [00:02<00:00, 17.92it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 20.54it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 19.03it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 17.41it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 20.94it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 18.89it/s]\n",
      "100%|██████████| 179/179 [00:14<00:00, 12.69it/s]\n",
      "100%|██████████| 26/26 [00:01<00:00, 18.53it/s]\n",
      "100%|██████████| 52/52 [00:02<00:00, 17.73it/s]\n",
      "100%|██████████| 33/33 [00:01<00:00, 18.09it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 20.55it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.49it/s]\n",
      "100%|██████████| 67/67 [00:03<00:00, 16.90it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 19.36it/s]\n",
      "100%|██████████| 19/19 [00:01<00:00, 18.82it/s]\n",
      "100%|██████████| 99/99 [00:06<00:00, 15.65it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 18.92it/s]\n",
      "100%|██████████| 29/29 [00:01<00:00, 19.02it/s]\n",
      "100%|██████████| 19/19 [00:00<00:00, 19.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 19.54it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 20.19it/s]\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "file_list = glob.glob('../data/eclip/*.h5')\n",
    "for file in file_list:\n",
    "    tf_name = file.split('/')[-1][:-7]\n",
    "    hyena_output = h5py.File('../data/eclip/Hyena/'+tf_name+'_200.h5','w')\n",
    "    batch_size = 128\n",
    "    file = h5py.File(file,'r')\n",
    "    for label in ('train','valid','test'):\n",
    "        output_cache = []  \n",
    "        for i in tqdm(range(0,len(file['X_'+label]),batch_size)):\n",
    "            seq = file['X_'+label][i:i+batch_size].astype('int')\n",
    "            seq = np.transpose(seq,(0,2,1))\n",
    "            seq = utils.onehot_to_seq(seq)\n",
    "            input_ids = tokenizer(list(seq), return_tensors=\"pt\",)[\"input_ids\"].to('cuda')\n",
    "            with torch.inference_mode():\n",
    "                hidden_states = model(input_ids).cpu().detach().numpy()\n",
    "            output_cache.extend(hidden_states)\n",
    "        hyena_output.create_dataset(name='x_'+label,data = np.array(output_cache),dtype = 'float32')\n",
    "        hyena_output.create_dataset(name='y_'+label,data = file['Y_'+label][:],dtype='int') \n",
    "    hyena_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MT Splice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:01<00:00, 21.33it/s]\n",
      "100%|██████████| 370/370 [00:18<00:00, 20.39it/s]\n",
      "100%|██████████| 1189/1189 [00:59<00:00, 19.89it/s]\n"
     ]
    }
   ],
   "source": [
    "file = h5py.File('../data/alternative_splicing/delta_logit.h5','r')\n",
    "hyena_output = h5py.File('../data/alternative_splicing/hyena_splice.h5','w')\n",
    "batch_size = 32\n",
    "max_len = 0\n",
    "for label in ('valid','test','train'):\n",
    "    l_cache = []\n",
    "    r_cache = [] \n",
    "    for i in tqdm(range(0,len(file['x_'+label]),batch_size)):\n",
    "        seq = file['x_'+label][i:i+batch_size].astype('int')\n",
    "        seq = utils.onehot_to_seq(seq)\n",
    "        clean_seq = seq\n",
    "        #clean_seq = [s if 'N' not in s else s.replace('N','[PAD]') for s in seq ]\n",
    "        l_seq = []\n",
    "        r_seq = []\n",
    "        for seq in clean_seq:\n",
    "            l_seq.append(seq[:400])\n",
    "            r_seq.append(seq[400:])\n",
    "        l_input = tokenizer(list(l_seq), return_tensors=\"pt\",)[\"input_ids\"].to('cuda')\n",
    "        r_input = tokenizer(list(r_seq), return_tensors=\"pt\",)[\"input_ids\"].to('cuda')\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            l_output = model(l_input).cpu().detach().numpy()\n",
    "            r_output = model(r_input).cpu().detach().numpy()\n",
    "        l_cache.extend(l_output)\n",
    "        r_cache.extend(r_output)\n",
    "    hyena_output.create_dataset(name='xl_'+label,data = np.array(l_cache),dtype = 'float32')\n",
    "    hyena_output.create_dataset(name='xr_'+label,data = np.array(r_cache),dtype = 'float32')\n",
    "    hyena_output.create_dataset(name='y_'+label,data = file['y_'+label][:],dtype='float32') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11840, 402, 256)\n",
      "(38028, 402, 256)\n",
      "(1088, 402, 256)\n",
      "(11840, 402, 256)\n",
      "(38028, 402, 256)\n",
      "(1088, 402, 256)\n",
      "(11840, 56, 2)\n",
      "(38028, 56, 2)\n",
      "(1088, 56, 2)\n"
     ]
    }
   ],
   "source": [
    "for key in hyena_output.keys():\n",
    "    print(hyena_output[key].shape)\n",
    "\n",
    "hyena_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-enlong data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:00<00:00, 129.04it/s]\n",
      "100%|██████████| 286/286 [00:02<00:00, 139.11it/s]\n",
      "100%|██████████| 36/36 [00:00<00:00, 131.96it/s]\n"
     ]
    }
   ],
   "source": [
    "hyena_output = h5py.File('../data/RNAenlong/hyena_embed.h5','w')\n",
    "file = h5py.File('../data/RNAenlong/insert_dataset.h5','r')\n",
    "batch_size = 32\n",
    "for dataset in ['test','train','valid']:\n",
    "    key = 'X_'+dataset\n",
    "    onehot = file[key]\n",
    "    string_seq = utils.onehot_to_seq(onehot)\n",
    "    token_seq = tokenizer(list(string_seq), return_tensors=\"pt\",)[\"input_ids\"].to('cuda')\n",
    "    output_cache = []\n",
    "    for seq_i in tqdm(range(0,len(token_seq),batch_size)):\n",
    "        with torch.inference_mode():\n",
    "            hidden_states = model(token_seq[seq_i:seq_i+batch_size]).cpu().detach().numpy()\n",
    "        output_cache.extend(hidden_states)\n",
    "    hyena_output.create_dataset(name=key,data = np.array(output_cache))\n",
    "    hyena_output.create_dataset(name='Y_'+dataset,data = file['Y_'+dataset][:])\n",
    "    hyena_output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
