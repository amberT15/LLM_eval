{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 18:08:36.191373: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import h5py \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import itertools\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='1'\n",
    "file_list = glob.glob('../data/eclip/*_200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 18:08:38.470782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78973 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:47:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "def di_nuc_frequency(seq_list):\n",
    "    key_list = list(itertools.product([0,1,2,3], [0,1,2,3]))\n",
    "    freq_array = []\n",
    "    pos_seq = np.argmax(seq_list,axis=1)\n",
    "    for seq in pos_seq:\n",
    "        count_dict =  dict(zip(key_list, [0]*len(key_list)))\n",
    "        for i in range(len(seq)-1):\n",
    "            entry = (seq[i],seq[i+1])\n",
    "            count_dict[entry] += 1\n",
    "        freq_array.append(list(count_dict.values()))\n",
    "    return np.array(freq_array)\n",
    "\n",
    "def rep_mlp(input_shape,output_shape = 1):\n",
    "     #initializer\n",
    "    initializer = keras.initializers.RandomNormal(mean=0.0, stddev=0.005)\n",
    "    #input layer\n",
    "    inputs = keras.Input(shape=input_shape, name='sequence')\n",
    "    nn = keras.layers.Dense(512,kernel_initializer=initializer)(inputs)\n",
    "    nn = keras.layers.BatchNormalization()(nn)\n",
    "    nn = keras.layers.Activation('relu')(nn)\n",
    "    nn = keras.layers.Dropout(0.5)(nn)\n",
    "\n",
    "    nn = keras.layers.Dense(256,kernel_initializer=initializer)(nn)\n",
    "    nn = keras.layers.BatchNormalization()(nn)\n",
    "    nn = keras.layers.Activation('relu')(nn)\n",
    "    nn = keras.layers.Dropout(0.5)(nn)\n",
    "\n",
    "    outputs = keras.layers.Dense(output_shape,activation = 'linear',kernel_initializer=initializer)(nn)\n",
    "\n",
    "    model =  keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "earlyStopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "            patience=10, restore_best_weights=True\n",
    "        )\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', factor=0.2,\n",
    "            patience=5, min_lr=1e-6)\n",
    "auroc = tf.keras.metrics.AUC(curve='ROC', name='auroc')\n",
    "aupr = tf.keras.metrics.AUC(curve='PR', name='aupr')\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False, label_smoothing=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nucleotide Logistic Regression\n",
    "exp = []\n",
    "test_accuracy = []\n",
    "test_auroc = []\n",
    "test_aupr = []\n",
    "model_list = []\n",
    "\n",
    "\n",
    "for file in file_list:\n",
    "    tf_name = file.split('/')[-1][:-7]\n",
    "    data = h5py.File(file,'r')\n",
    "    x_train = data['x_train'][:,:4,:]\n",
    "    y_train = data['y_train'][:]\n",
    "    x_valid = data['x_valid'][:,:4,:]\n",
    "    y_valid = data['y_valid'][:]\n",
    "    x_test = data['x_test'][:,:4,:]\n",
    "    y_test = data['y_test'][:]\n",
    "    #Train Regression Model\n",
    "    mean_train = np.mean(np.concatenate((x_train,x_valid)),axis=-1)\n",
    "    target_train = np.concatenate((y_train,y_valid))\n",
    "    mean_model = LogisticRegression(random_state=0).fit(mean_train,np.squeeze(target_train))\n",
    "    #Predict + Eval\n",
    "    mean_predict = mean_model.predict(np.mean(x_test,axis=-1))\n",
    "    test_accuracy.append(metrics.accuracy_score(y_test,mean_predict))\n",
    "    test_auroc.append(metrics.roc_auc_score(y_test,mean_predict))\n",
    "    test_aupr.append(metrics.average_precision_score(y_test,mean_predict))\n",
    "    model_list.append('Mean One-hot logistic regression')\n",
    "    exp.append(tf_name)\n",
    "\n",
    "perf = pd.DataFrame({'TF':exp,'Accuracy':test_accuracy,'AUROC':test_auroc,'AUPR':test_aupr,'Model':model_list})\n",
    "perf.to_csv('./result/chip_result/seq_perf_logistic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ztang/.conda/envs/jax_tf/lib/python3.9/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "2024-02-13 17:08:18.948059: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-02-13 17:08:18.951258: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x556cb2737480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-13 17:08:18.951278: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2024-02-13 17:08:18.954606: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-13 17:08:19.054147: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8800\n",
      "2024-02-13 17:08:19.150135: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "282/282 [==============================] - 0s 1ms/step - loss: 0.6160 - accuracy: 0.6627 - auroc: 0.7186 - aupr: 0.7499\n",
      "282/282 [==============================] - 0s 1ms/step - loss: 0.6123 - accuracy: 0.6623 - auroc: 0.7200 - aupr: 0.7484\n",
      "282/282 [==============================] - 0s 1ms/step - loss: 0.6129 - accuracy: 0.6669 - auroc: 0.7179 - aupr: 0.7473\n",
      "282/282 [==============================] - 0s 1ms/step - loss: 0.6094 - accuracy: 0.6656 - auroc: 0.7188 - aupr: 0.7487\n",
      "282/282 [==============================] - 0s 1ms/step - loss: 0.6159 - accuracy: 0.6643 - auroc: 0.7188 - aupr: 0.7480\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.7216 - auroc: 0.8078 - aupr: 0.8328\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5360 - accuracy: 0.7249 - auroc: 0.8075 - aupr: 0.8307\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.7300 - auroc: 0.8083 - aupr: 0.8330\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5301 - accuracy: 0.7300 - auroc: 0.8084 - aupr: 0.8332\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5295 - accuracy: 0.7245 - auroc: 0.8083 - aupr: 0.8331\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 0.5604 - accuracy: 0.7215 - auroc: 0.7674 - aupr: 0.8017\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 0.5550 - accuracy: 0.7195 - auroc: 0.7672 - aupr: 0.8021\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 0.5596 - accuracy: 0.7227 - auroc: 0.7704 - aupr: 0.8030\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.7173 - auroc: 0.7675 - aupr: 0.8014\n",
      "304/304 [==============================] - 0s 1ms/step - loss: 0.5731 - accuracy: 0.7181 - auroc: 0.7681 - aupr: 0.7985\n",
      "546/546 [==============================] - 1s 1ms/step - loss: 0.6610 - accuracy: 0.6059 - auroc: 0.6410 - aupr: 0.6173\n",
      "546/546 [==============================] - 1s 1ms/step - loss: 0.6612 - accuracy: 0.6045 - auroc: 0.6408 - aupr: 0.6178\n",
      "546/546 [==============================] - 1s 1ms/step - loss: 0.6616 - accuracy: 0.6036 - auroc: 0.6400 - aupr: 0.6162\n",
      "546/546 [==============================] - 1s 1ms/step - loss: 0.6608 - accuracy: 0.6053 - auroc: 0.6415 - aupr: 0.6176\n",
      "546/546 [==============================] - 1s 1ms/step - loss: 0.6611 - accuracy: 0.6047 - auroc: 0.6409 - aupr: 0.6175\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7583 - auroc: 0.7913 - aupr: 0.7683\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5415 - accuracy: 0.7618 - auroc: 0.7924 - aupr: 0.7721\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5474 - accuracy: 0.7597 - auroc: 0.7951 - aupr: 0.7749\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5658 - accuracy: 0.7594 - auroc: 0.7951 - aupr: 0.7684\n",
      "92/92 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.7563 - auroc: 0.7913 - aupr: 0.7672\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6563 - accuracy: 0.6254 - auroc: 0.6512 - aupr: 0.6573\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.6219 - auroc: 0.6504 - aupr: 0.6612\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.6187 - auroc: 0.6505 - aupr: 0.6624\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.6203 - auroc: 0.6517 - aupr: 0.6599\n",
      "99/99 [==============================] - 0s 1ms/step - loss: 0.6553 - accuracy: 0.6235 - auroc: 0.6520 - aupr: 0.6603\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.7671 - auroc: 0.8271 - aupr: 0.8069\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 0.5143 - accuracy: 0.7683 - auroc: 0.8305 - aupr: 0.8097\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7656 - auroc: 0.8277 - aupr: 0.8053\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 0.5302 - accuracy: 0.7700 - auroc: 0.8293 - aupr: 0.8073\n",
      "229/229 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.7611 - auroc: 0.8304 - aupr: 0.8067\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6577 - auroc: 0.7030 - aupr: 0.6652\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6331 - accuracy: 0.6646 - auroc: 0.6996 - aupr: 0.6570\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.6561 - auroc: 0.6994 - aupr: 0.6574\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.6565 - auroc: 0.7009 - aupr: 0.6581\n",
      "81/81 [==============================] - 0s 1ms/step - loss: 0.6287 - accuracy: 0.6623 - auroc: 0.7020 - aupr: 0.6583\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.5633 - auroc: 0.5971 - aupr: 0.6174\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 0.6702 - accuracy: 0.5612 - auroc: 0.5985 - aupr: 0.6190\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 0.6645 - accuracy: 0.5681 - auroc: 0.5976 - aupr: 0.6175\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.5598 - auroc: 0.5985 - aupr: 0.6157\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 0.6649 - accuracy: 0.5672 - auroc: 0.6000 - aupr: 0.6188\n",
      "226/226 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.6346 - auroc: 0.6721 - aupr: 0.6815\n",
      "226/226 [==============================] - 0s 1ms/step - loss: 0.6404 - accuracy: 0.6389 - auroc: 0.6760 - aupr: 0.6861\n",
      "226/226 [==============================] - 0s 1ms/step - loss: 0.6454 - accuracy: 0.6335 - auroc: 0.6687 - aupr: 0.6796\n",
      "226/226 [==============================] - 0s 1ms/step - loss: 0.6452 - accuracy: 0.6299 - auroc: 0.6685 - aupr: 0.6777\n",
      "226/226 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.6337 - auroc: 0.6739 - aupr: 0.6813\n"
     ]
    }
   ],
   "source": [
    "## Nucleotide MLP\n",
    "exp = []\n",
    "test_accuracy = []\n",
    "test_auroc = []\n",
    "test_aupr = []\n",
    "model_list = []\n",
    "for file in file_list:\n",
    "    tf_name = file.split('/')[-1][:-7]\n",
    "    data = h5py.File(file,'r')\n",
    "    x_train = data['x_train'][:,:4,:]\n",
    "    y_train = data['y_train'][:]\n",
    "    x_valid = data['x_valid'][:,:4,:]\n",
    "    y_valid = data['y_valid'][:]\n",
    "    x_test = data['x_test'][:,:4,:]\n",
    "    y_test = data['y_test'][:]\n",
    "\n",
    "    mean_train = np.mean(x_train,axis=-1)\n",
    "    mean_valid = np.mean(x_valid,axis=-1)\n",
    "    mean_test = np.mean(x_test,axis=-1)\n",
    "\n",
    "    #Train MLP Model\n",
    "    for i in range(5):\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model = rep_mlp((4),1)\n",
    "        model.compile(loss = loss,\n",
    "                    metrics=['accuracy',auroc,aupr],\n",
    "                    optimizer=optimizer)\n",
    "        \n",
    "        result = model.fit(mean_train,y_train,\n",
    "            batch_size=256,\n",
    "            validation_data=(mean_valid,y_valid),\n",
    "            epochs=100,\n",
    "            verbose=0,\n",
    "            callbacks=[earlyStopping_callback,reduce_lr]\n",
    "        )\n",
    "        _, acc, roc, pr = model.evaluate(mean_test,y_test)\n",
    "        exp.append(tf_name)\n",
    "        model_list.append('One-hot MLP')\n",
    "        test_accuracy.append(acc)\n",
    "        test_auroc.append(roc)\n",
    "        test_aupr.append(pr)\n",
    "\n",
    "perf = pd.DataFrame({'TF':exp,'Accuracy':test_accuracy,'AUROC':test_auroc,'AUPR':test_aupr,'Model':model_list})\n",
    "perf.to_csv('./result/chip_result/seq_perf_MLP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ztang/.conda/envs/jax_tf/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## Nucleotide Logistic Regression\n",
    "exp = []\n",
    "test_accuracy = []\n",
    "test_auroc = []\n",
    "test_aupr = []\n",
    "model_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    tf_name = file.split('/')[-1][:-12]\n",
    "    data = h5py.File(file,'r')\n",
    "    x_train = data['X_train'][:,:4,:]\n",
    "    y_train = data['Y_train'][:]\n",
    "    x_valid = data['X_valid'][:,:4,:]\n",
    "    y_valid = data['Y_valid'][:]\n",
    "    x_test = data['X_test'][:,:4,:]\n",
    "    y_test = data['Y_test'][:]\n",
    "    #Train Regression Model\n",
    "    x_train = np.concatenate((x_train,x_valid))\n",
    "    y_train = np.concatenate((y_train,y_valid))\n",
    "    x_freq = di_nuc_frequency(x_train)\n",
    "    dinuc_model = LogisticRegression(random_state=0).fit(x_freq,np.squeeze(y_train))\n",
    "    #Predict + Eval\n",
    "    mean_predict = dinuc_model.predict(di_nuc_frequency(x_test))\n",
    "    test_accuracy.append(metrics.accuracy_score(y_test,mean_predict))\n",
    "    test_auroc.append(metrics.roc_auc_score(y_test,mean_predict))\n",
    "    test_aupr.append(metrics.average_precision_score(y_test,mean_predict))\n",
    "    model_list.append('Dinucleotide logistic regression')\n",
    "    exp.append(tf_name)\n",
    "\n",
    "perf = pd.DataFrame({'TF':exp,'Accuracy':test_accuracy,'AUROC':test_auroc,'AUPR':test_aupr,'Model':model_list})\n",
    "perf.to_csv('./result/eclip_result/dinuc_perf_logistic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ztang/.conda/envs/jax_tf/lib/python3.9/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "2024-02-13 18:10:31.734455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-02-13 18:10:31.737773: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f374806e5f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-02-13 18:10:31.737793: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2024-02-13 18:10:31.741319: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-02-13 18:10:31.840507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8800\n",
      "2024-02-13 18:10:31.937264: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.9407 - auroc: 0.9805 - aupr: 0.9740\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.9433 - auroc: 0.9807 - aupr: 0.9739\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2089 - accuracy: 0.9215 - auroc: 0.9841 - aupr: 0.9809\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.9389 - auroc: 0.9817 - aupr: 0.9741\n",
      "36/36 [==============================] - 0s 1ms/step - loss: 0.3048 - accuracy: 0.9258 - auroc: 0.9775 - aupr: 0.9726\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.9191 - auroc: 0.9722 - aupr: 0.9754\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2601 - accuracy: 0.9203 - auroc: 0.9690 - aupr: 0.9693\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2331 - accuracy: 0.9191 - auroc: 0.9714 - aupr: 0.9731\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.9175 - auroc: 0.9722 - aupr: 0.9754\n",
      "102/102 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.9157 - auroc: 0.9665 - aupr: 0.9704\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.5145 - accuracy: 0.7497 - auroc: 0.8289 - aupr: 0.8196\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.7534 - auroc: 0.8277 - aupr: 0.8180\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.5437 - accuracy: 0.7417 - auroc: 0.8261 - aupr: 0.8156\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.7493 - auroc: 0.8273 - aupr: 0.8184\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 0.5227 - accuracy: 0.7428 - auroc: 0.8255 - aupr: 0.8140\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8465 - auroc: 0.9237 - aupr: 0.9290\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3857 - accuracy: 0.8377 - auroc: 0.9188 - aupr: 0.9204\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4246 - accuracy: 0.8202 - auroc: 0.9159 - aupr: 0.9219\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.4154 - accuracy: 0.8085 - auroc: 0.9132 - aupr: 0.9130\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 0.3766 - accuracy: 0.8501 - auroc: 0.9237 - aupr: 0.9292\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4549 - accuracy: 0.7901 - auroc: 0.9015 - aupr: 0.9095\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4452 - accuracy: 0.8280 - auroc: 0.9027 - aupr: 0.9094\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7945 - auroc: 0.8961 - aupr: 0.9065\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4354 - accuracy: 0.8252 - auroc: 0.8987 - aupr: 0.9087\n",
      "57/57 [==============================] - 0s 1ms/step - loss: 0.4434 - accuracy: 0.7940 - auroc: 0.9025 - aupr: 0.9134\n",
      "205/205 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7586 - auroc: 0.8529 - aupr: 0.8522\n",
      "205/205 [==============================] - 0s 1ms/step - loss: 0.4909 - accuracy: 0.7719 - auroc: 0.8576 - aupr: 0.8531\n",
      "205/205 [==============================] - 0s 1ms/step - loss: 0.5236 - accuracy: 0.7535 - auroc: 0.8542 - aupr: 0.8523\n",
      "205/205 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7762 - auroc: 0.8644 - aupr: 0.8645\n",
      "205/205 [==============================] - 0s 1ms/step - loss: 0.4898 - accuracy: 0.7685 - auroc: 0.8608 - aupr: 0.8576\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.5162 - accuracy: 0.7348 - auroc: 0.8847 - aupr: 0.8823\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4700 - accuracy: 0.7873 - auroc: 0.8900 - aupr: 0.8925\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7940 - auroc: 0.8856 - aupr: 0.8920\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7865 - auroc: 0.8796 - aupr: 0.8871\n",
      "38/38 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7823 - auroc: 0.8990 - aupr: 0.9044\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.2288 - accuracy: 0.9282 - auroc: 0.9768 - aupr: 0.9749\n",
      "76/76 [==============================] - 0s 2ms/step - loss: 0.2786 - accuracy: 0.9323 - auroc: 0.9743 - aupr: 0.9718\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.2520 - accuracy: 0.9253 - auroc: 0.9765 - aupr: 0.9768\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.2312 - accuracy: 0.9273 - auroc: 0.9775 - aupr: 0.9762\n",
      "76/76 [==============================] - 0s 1ms/step - loss: 0.2601 - accuracy: 0.9240 - auroc: 0.9769 - aupr: 0.9758\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.4883 - accuracy: 0.7665 - auroc: 0.8584 - aupr: 0.8443\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7607 - auroc: 0.8530 - aupr: 0.8377\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.4895 - accuracy: 0.7673 - auroc: 0.8534 - aupr: 0.8389\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7712 - auroc: 0.8590 - aupr: 0.8455\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7544 - auroc: 0.8581 - aupr: 0.8462\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7351 - auroc: 0.8224 - aupr: 0.8114\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7262 - auroc: 0.8115 - aupr: 0.8016\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7336 - auroc: 0.8166 - aupr: 0.8146\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7366 - auroc: 0.8150 - aupr: 0.8073\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7321 - auroc: 0.8206 - aupr: 0.8089\n"
     ]
    }
   ],
   "source": [
    "## Nucleotide MLP\n",
    "exp = []\n",
    "test_accuracy = []\n",
    "test_auroc = []\n",
    "test_aupr = []\n",
    "model_list = []\n",
    "\n",
    "for file in file_list:\n",
    "    tf_name = file.split('/')[-1][:-7]\n",
    "    data = h5py.File(file,'r')\n",
    "    x_train = data['X_train'][:,:4,:]\n",
    "    y_train = data['Y_train'][:]\n",
    "    x_valid = data['X_valid'][:,:4,:]\n",
    "    y_valid = data['Y_valid'][:]\n",
    "    x_test = data['X_test'][:,:4,:]\n",
    "    y_test = data['Y_test'][:]\n",
    "    #Train Regression Model\n",
    "    x_train = di_nuc_frequency(x_train)\n",
    "    x_valid = di_nuc_frequency(x_valid)\n",
    "    x_test = di_nuc_frequency(x_test)\n",
    "    #Train MLP Model\n",
    "    for i in range(5):\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "        model = rep_mlp((16),1)\n",
    "        model.compile(loss = loss,\n",
    "                    metrics=['accuracy',auroc,aupr],\n",
    "                    optimizer=optimizer)\n",
    "        \n",
    "        result = model.fit(x_train,y_train,\n",
    "            batch_size=256,\n",
    "            validation_data=(x_valid,y_valid),\n",
    "            epochs=100,\n",
    "            verbose=0,\n",
    "            callbacks=[earlyStopping_callback,reduce_lr]\n",
    "        )\n",
    "        _, acc, roc, pr = model.evaluate(x_test,y_test)\n",
    "        exp.append(tf_name)\n",
    "        model_list.append('Dinucletodie MLP')\n",
    "        test_accuracy.append(acc)\n",
    "        test_auroc.append(roc)\n",
    "        test_aupr.append(pr)\n",
    "\n",
    "perf = pd.DataFrame({'TF':exp,'Accuracy':test_accuracy,'AUROC':test_auroc,'AUPR':test_aupr,'Model':model_list})\n",
    "perf.to_csv('./result/eclip_result/dinuc_perf_MLP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
