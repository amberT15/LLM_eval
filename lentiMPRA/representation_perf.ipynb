{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 18:23:50.952529: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import mpra_model\n",
    "import h5py\n",
    "importlib.reload(mpra_model)\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "import scipy.stats\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data/lenti_MPRA_embed/sei_HepG2.h5'\n",
    "model_file = '../model/lenti_MPRA/lenti_MPRA_embed/HepG2/sei.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 18:23:56.540902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78973 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:07:00.0, compute capability: 8.0\n",
      "/home/ztang/.conda/envs/jax_tf/lib/python3.9/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 18:24:01.721400: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [113300,960,16]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-11-27 18:24:01.721619: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [113300]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-11-27 18:24:03.654953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8800\n",
      "2023-11-27 18:24:04.303167: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-11-27 18:24:04.304696: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fde9c061860 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-11-27 18:24:04.304714: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A100 80GB PCIe, Compute Capability 8.0\n",
      "2023-11-27 18:24:04.307621: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-11-27 18:24:04.411228: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - ETA: 0s - loss: 0.3283 - mse: 0.3283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 18:24:17.471301: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype float and shape [12589,960,16]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-11-27 18:24:17.471523: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [12589]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "443/443 [==============================] - 17s 27ms/step - loss: 0.3283 - mse: 0.3283 - val_loss: 0.6618 - val_mse: 0.6618 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2942 - mse: 0.2942 - val_loss: 0.3510 - val_mse: 0.3510 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "443/443 [==============================] - 10s 24ms/step - loss: 0.2863 - mse: 0.2863 - val_loss: 0.3578 - val_mse: 0.3578 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2821 - mse: 0.2821 - val_loss: 0.3055 - val_mse: 0.3055 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2783 - mse: 0.2783 - val_loss: 0.2988 - val_mse: 0.2988 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2753 - mse: 0.2753 - val_loss: 0.3059 - val_mse: 0.3059 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2722 - mse: 0.2722 - val_loss: 0.2993 - val_mse: 0.2993 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2702 - mse: 0.2702 - val_loss: 0.2804 - val_mse: 0.2804 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2676 - mse: 0.2676 - val_loss: 0.2958 - val_mse: 0.2958 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2644 - mse: 0.2644 - val_loss: 0.2993 - val_mse: 0.2993 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2616 - mse: 0.2616 - val_loss: 0.2750 - val_mse: 0.2750 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2586 - mse: 0.2586 - val_loss: 0.2827 - val_mse: 0.2827 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2560 - mse: 0.2560 - val_loss: 0.2908 - val_mse: 0.2908 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2529 - mse: 0.2529 - val_loss: 0.2825 - val_mse: 0.2825 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2522 - mse: 0.2522 - val_loss: 0.3366 - val_mse: 0.3366 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2475 - mse: 0.2475 - val_loss: 0.2793 - val_mse: 0.2793 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2401 - mse: 0.2401 - val_loss: 0.2721 - val_mse: 0.2721 - lr: 2.0000e-05\n",
      "Epoch 18/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2373 - mse: 0.2373 - val_loss: 0.2746 - val_mse: 0.2746 - lr: 2.0000e-05\n",
      "Epoch 19/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2344 - mse: 0.2344 - val_loss: 0.2707 - val_mse: 0.2707 - lr: 2.0000e-05\n",
      "Epoch 20/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2337 - mse: 0.2337 - val_loss: 0.2698 - val_mse: 0.2698 - lr: 2.0000e-05\n",
      "Epoch 21/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2316 - mse: 0.2316 - val_loss: 0.2692 - val_mse: 0.2692 - lr: 2.0000e-05\n",
      "Epoch 22/100\n",
      "443/443 [==============================] - 11s 25ms/step - loss: 0.2298 - mse: 0.2298 - val_loss: 0.2688 - val_mse: 0.2688 - lr: 2.0000e-05\n",
      "Epoch 23/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2288 - mse: 0.2288 - val_loss: 0.2697 - val_mse: 0.2697 - lr: 2.0000e-05\n",
      "Epoch 24/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2282 - mse: 0.2282 - val_loss: 0.2686 - val_mse: 0.2686 - lr: 2.0000e-05\n",
      "Epoch 25/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2260 - mse: 0.2260 - val_loss: 0.2705 - val_mse: 0.2705 - lr: 2.0000e-05\n",
      "Epoch 26/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2251 - mse: 0.2251 - val_loss: 0.2699 - val_mse: 0.2699 - lr: 2.0000e-05\n",
      "Epoch 27/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2240 - mse: 0.2240 - val_loss: 0.2711 - val_mse: 0.2711 - lr: 2.0000e-05\n",
      "Epoch 28/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2222 - mse: 0.2222 - val_loss: 0.2730 - val_mse: 0.2730 - lr: 2.0000e-05\n",
      "Epoch 29/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2214 - mse: 0.2214 - val_loss: 0.2746 - val_mse: 0.2746 - lr: 2.0000e-05\n",
      "Epoch 30/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2206 - mse: 0.2206 - val_loss: 0.2710 - val_mse: 0.2710 - lr: 4.0000e-06\n",
      "Epoch 31/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2193 - mse: 0.2193 - val_loss: 0.2725 - val_mse: 0.2725 - lr: 4.0000e-06\n",
      "Epoch 32/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2185 - mse: 0.2185 - val_loss: 0.2724 - val_mse: 0.2724 - lr: 4.0000e-06\n",
      "Epoch 33/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2190 - mse: 0.2190 - val_loss: 0.2708 - val_mse: 0.2708 - lr: 4.0000e-06\n",
      "Epoch 34/100\n",
      "443/443 [==============================] - 11s 24ms/step - loss: 0.2187 - mse: 0.2187 - val_loss: 0.2701 - val_mse: 0.2701 - lr: 4.0000e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 18:30:10.760018: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [13988]\n",
      "\t [[{{node Placeholder/_1}}]]\n",
      "2023-11-27 18:30:10.760246: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype double and shape [13988]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 8ms/step\n",
      "PearsonRResult(statistic=0.7527342712209032, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "cnn_config = {\n",
    "    'activation':'exponential',\n",
    "    'reduce_dim': 128,\n",
    "    'conv1_filter':196,\n",
    "    'conv1_kernel':7,\n",
    "    'dropout1':0.2,\n",
    "    'res_filter':5,\n",
    "    'res_layers':3,\n",
    "    'res_pool':5,\n",
    "    'res_dropout':0.2,\n",
    "    'conv2_filter':256,\n",
    "    'conv2_kernel':7,\n",
    "    'pool2_size':4,\n",
    "    'dropout2':0.2,\n",
    "    'dense':512,\n",
    "    'dense2':256,\n",
    "    'l_rate':0.0001\n",
    "}\n",
    "\n",
    "file = h5py.File(data_file,'r')\n",
    "seq = file['seq'][()]\n",
    "target = file['mean'][()]\n",
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(seq,target,random_state=42,test_size=0.1)\n",
    "x_train,x_valid,y_train,y_valid = model_selection.train_test_split(x_train,y_train,random_state=42,test_size=0.1)\n",
    "with tf.device(\"CPU\"):\n",
    "        trainset = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(256*4).batch(256)\n",
    "        validset = tf.data.Dataset.from_tensor_slices((x_valid,y_valid)).shuffle(256*4).batch(256)\n",
    "        testset = tf.data.Dataset.from_tensor_slices((x_test,y_test)).shuffle(256*4).batch(256)\n",
    "\n",
    "model = mpra_model.rep_cnn(seq[0].shape,cnn_config)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=cnn_config['l_rate'])\n",
    "loss = tf.keras.losses.MeanSquaredError()\n",
    "model.compile(optimizer=optimizer,\n",
    "                loss=loss,\n",
    "                metrics=['mse'])\n",
    "earlyStopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "        patience=10, restore_best_weights=True\n",
    "    )\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss', factor=0.2,\n",
    "        patience=5, min_lr=1e-8)\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                    model_file,\n",
    "                                    monitor='val_loss',\n",
    "                                    save_best_only=True,\n",
    "                                    mode = 'min',\n",
    "                                    save_freq='epoch',)\n",
    "model.fit(\n",
    "        trainset,\n",
    "        epochs=100,\n",
    "        batch_size=512,\n",
    "        shuffle=True,\n",
    "        validation_data = validset,\n",
    "        callbacks=[earlyStopping_callback,reduce_lr\n",
    "                   ,checkpoint]\n",
    "    )\n",
    "pred_y = []\n",
    "y_test = []\n",
    "for i,(x,y) in enumerate(testset):\n",
    "    pred_y.extend(model.predict(x))\n",
    "    y_test.extend(y)\n",
    "\n",
    "print(scipy.stats.pearsonr(np.squeeze(pred_y),np.squeeze(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
